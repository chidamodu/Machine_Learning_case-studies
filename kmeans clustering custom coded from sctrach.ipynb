{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"]=(12, 12)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(read the input file here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check for null and missing values in the dataset. Devise a plan re how to fill those values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Get the ID column separately and drop it in the dataset\n",
    "\n",
    "salesresp=df[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X will be a numpy array. Remember that X here has been already normalized in order to get rid of the curse of \n",
    "dimensionality\n",
    "\n",
    "X=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used sklearn kmeans ELBOW method to find the optimal value for k\n",
    "from sklearn.cluster import kmeans\n",
    "wcss=[]\n",
    "\n",
    "#we, most often, assume the max number of clsuter would be 10\n",
    "#can judge the number of clusters by averaging\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans=KMeans(n_clusters=i, init='k-means++', random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)#inertia is the formula used to segregate the data points into clusters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the ELBOW method to get the optimal value of k\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Percent of variance explained_wcss')\n",
    "plt.show()\n",
    "\n",
    "Observation: sample\n",
    "the second elbow falls at 3 so will go with k=3 clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coding kmeans from scratch:\n",
    "    \n",
    "def kmeans(X, k, max_iter=1000):\n",
    "\tcenters=[tuple(c) for c in random.sample(X.tolist(), k)]#it randomly picks k elements from the input array X\n",
    "\t#X.tolist()-this is because X is a numpy array and so have to convert it into a list of values\n",
    "\n",
    "\n",
    "\tfor i in range(max_iter):\n",
    "\t\tclusters=defaultdict(list)\n",
    "\t\tclusters_repid=defaultdict(list)\n",
    "\t\trepid=[]\n",
    "\t\tfor value in X:\n",
    "\t\t\tind=np.where(X==value)\n",
    "\t\t\tdistance=[euclidean(value, x0) for x0 in centers]#find the euclidean distance between each value in X and each point in centers\n",
    "\t\t\tresult=centers[np.argmin(distance)]#np.argmin returns the index of the minimum distance. find the value of the index in centers and append it to clusters cause that is the centroid\n",
    "\t\t\tclusters[result].append(value)\n",
    "\t\t\tclusters_repid[result].extend(list(ind))#list(ind) is because ind is also a numpy array returned by\n",
    "\t\t\t#statement np.where\n",
    "\t\t\t\n",
    "\t\t\t# get the index of value with re to the dataframe and use the index finally to pull the SalesRep_ID value\n",
    "\t\t\t# from the dataframe\n",
    "\n",
    "\t\tnew_centers=[]\n",
    "\t\tfor c, p in clusters.items():\n",
    "\t\t\tnew_centers.append(tuple(np.mean(p, axis=0)))\n",
    "\n",
    "\t\tif set(new_centers)==set(centers):#if the earlier version of center the same as the newly created centers then break the loop\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcenters=new_centers#if not break then assign the newly created centers to the earlier version, i.e., centers and continue with the next iteration\n",
    "\n",
    "\treturn clusters, clusters_repid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, clusters_repid=kmeans(X, k=3, max_iter=5)#X here is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Can use this to figure out the optimal value for k. This is just a part of a whole coding...this formula is what we use\n",
    "to calculate at which value of k the error is the least\n",
    "\n",
    "def sum_squared_error(clusters):\n",
    "\tsum_error=0\n",
    "\tfor cen, point in clusters.items():\n",
    "\t\tfor i in point:\n",
    "\t\t\tsum_error+=euclidean(i, cen)**2\n",
    "\treturn sum_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_clusters_labels(clusters, clusters_repid, salesrep):\n",
    "\tl=0\n",
    "\t\n",
    "\tnew_X=[]\n",
    "\tlabels=[]\n",
    "\tfor_repid=[]\n",
    "\n",
    "\tfor center, point in clusters.items():\n",
    "\t\tfor pt in point:\n",
    "\t\t\tnew_X.append(pt)\n",
    "\t\n",
    "\t\t\tlabels.append([l])#not sure whether [l] is necessary here\n",
    "\n",
    "\t\tl+=1\n",
    "\n",
    "\tfor c, p in clusters_repid.items():\n",
    "\t\tfor pts in p:\n",
    "\t\t\tfor_repid.append(salesrep.loc[pts, 'SALESREP_ID'])\n",
    "\n",
    "\treturn labels, new_X, for_repid#ideally it would be better to return lists so it is easier to use later in the\n",
    "\t#process especially to loop through and get salesrepid from a pandas dataset. it's not an easy task to do all this\n",
    "\t#using numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, new_X, for_repid=turn_clusters_labels(clusters, clusters_repid, salesrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X#is a numpy arraty\n",
    "\n",
    "X_new_fair=np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To plot list of values with varying lengths, convert the list of values into a dataframe columns\n",
    "\n",
    "df_visuals=pd.DataFrame.from.dict({\"labels\":labels, \"X_values\":X_new_fair[:, 0].tolist(), \"SalesRepID\":for_repid[0].tolist()}, orient='index').T\n",
    "\n",
    "important things to note:\n",
    "X_new_fair has two columns that can be accessed as X_new_fair[:, 0] and X_new_fair[:, 1]\n",
    "Likewise for_repid has two columns and that can be accessed as for_repid[0] and for_repid[1]\n",
    "This is primarily because of how the random samples have been formed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if u want to delete the square brackets of lists from the values in a column\n",
    "\n",
    "df_visuals[\"some column\"]=df_visuals[\"some column\"].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample:\n",
    "    \n",
    "import seaborn as sns; sns.set()\n",
    "cmap=sns.cubehelix_palette(dark=0.8, light=4.8, as_cmap=True)\n",
    "ax=sns.scatterplot(x='X_values', y='SalesRepID', hue='labels', palette=\"inferno\",data=df_visuals, sizes=(1300, 2500))\n",
    "ax.set_title('Clusters of similar SalesRepID ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In case if you have to plot all 2D plots with re to every feature in the input dataset - check the 2D plot from \n",
    "galvanize repo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Another way to plot\n",
    "\n",
    "ax=df_visuals.plot.scatter(x='X_values', y='SalesRepID', s=330, c='labels', colormap='viridis')\n",
    "plt.title('')\n",
    "plt.xlabel('X_values')\n",
    "plt.ylabel('SalesRepID')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
