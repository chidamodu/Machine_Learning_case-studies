{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using pandas read_json command with orient='records' option to display the dataframe\n",
    "import pandas as pd\n",
    "df1=pd.read_json('file.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time is represented in unix epoch time format in the dataset and so using unit='s' in pd.to_datetime to tranform date-time\n",
    "df1['approx_payout_date'] =  pd.to_datetime(df1['approx_payout_date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-02-13 12:00:00\n",
       "1   2011-02-03 08:00:00\n",
       "2   2011-01-28 00:00:00\n",
       "3   2014-01-06 00:00:00\n",
       "4   2011-02-17 00:00:00\n",
       "Name: approx_payout_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['approx_payout_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['event_created'] =  pd.to_datetime(df1['event_created'], unit='s')\n",
    "df1['event_end'] =  pd.to_datetime(df1['event_end'], unit='s')\n",
    "df1['event_start'] =  pd.to_datetime(df1['event_start'], unit='s')\n",
    "df1['user_created'] =  pd.to_datetime(df1['user_created'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraudster_event', 'premium', 'spammer_warn', 'fraudster',\n",
       "       'spammer_limited', 'spammer_noinvite', 'locked', 'tos_lock',\n",
       "       'tos_warn', 'fraudster_att', 'spammer_web', 'spammer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['acct_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acct_type', 'approx_payout_date', 'body_length', 'channels', 'country',\n",
       "       'currency', 'delivery_method', 'description', 'email_domain',\n",
       "       'event_created', 'event_end', 'event_published', 'event_start',\n",
       "       'fb_published', 'gts', 'has_analytics', 'has_header', 'has_logo',\n",
       "       'listed', 'name', 'name_length', 'num_order', 'num_payouts',\n",
       "       'object_id', 'org_desc', 'org_facebook', 'org_name', 'org_twitter',\n",
       "       'payee_name', 'payout_type', 'previous_payouts', 'sale_duration',\n",
       "       'sale_duration2', 'show_map', 'ticket_types', 'user_age',\n",
       "       'user_created', 'user_type', 'venue_address', 'venue_country',\n",
       "       'venue_latitude', 'venue_longitude', 'venue_name', 'venue_state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coulmns of the dataframe\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what i think could be useful features:\n",
    "'acct_type', 'approx_payout_date','country','currency''email_domain','sale_duration''sale_duration2'\n",
    "       'event_created', 'event_end', 'event_published', 'event_start',\n",
    "       'fb_published''num_order', 'num_payouts''org_facebook', 'org_name', 'org_twitter''user_type''venue_name', 'venue_state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  3., nan])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obviously need more details about the delivery_method\n",
    "df1['delivery_method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gmail.com', 'ruf.org', 'pvsd.k12.ca.us', ..., 'abdcycling.com',\n",
       "       'newcastle-cu.com', 'sbm.ie'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['email_domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   4,   5, 103,   2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#could visualize using user_type. if a user_type entails both fraud and non-fraud transactions then it might be a good idea to \n",
    "#revise the categories for more clarity!\n",
    "\n",
    "df1['user_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#expanding the lists of dictionaries in df1['ticket_types'] to a dataframe\n",
    "res=[]\n",
    "for i in df1['ticket_types']:\n",
    "    for j in i:\n",
    "        res.append(j)\n",
    "df_ticket = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expanding the lists of dictionaries in df1['previous_payouts'] to a dataframe but this leads to a dataframe of length:1097472\n",
    "#\n",
    "ans=[]\n",
    "for i in df1['previous_payouts']:\n",
    "    for j in i:\n",
    "        ans.append(j)\n",
    "df_payouts = pd.DataFrame.from_dict(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097472"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_payouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'IE', '', 'FR', 'CA', 'GB', 'AU', 'ES', 'BE', 'NL', 'DE',\n",
       "       'NZ', 'United Kingdom', 'Australia', 'AT', 'Canada', 'AUSTRALIA',\n",
       "       'UNITED KINGDOM', 'Eventbrite', 'EVENTBRITE', 'EVENT', 'ICELAND',\n",
       "       'UK', 'France', 'England', 'Indonesia', 'New Zealand', 'Germany',\n",
       "       'Thailand'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this list of countries is from the list of dictionaries of df1['previous_payouts']\n",
    "df_payouts['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'IE', 'FR', 'CA', 'GB', '', 'AU', 'ES', 'NL', 'DE', 'VN',\n",
       "       'MY', 'NZ', 'PK', 'MA', 'AR', 'MX', 'CH', None, 'SG', 'TH', 'BE',\n",
       "       'PH', 'A1', 'CI', 'AT', 'ID', 'PS', 'PT', 'TR', 'NI', 'KE', 'IT',\n",
       "       'HU', 'RS', 'RO', 'NG', 'CZ', 'PR', 'AE', 'BS', 'KH', 'JM', 'IN',\n",
       "       'NA', 'FI', 'HR', 'BG', 'VI', 'TJ', 'GH', 'PE', 'QA', 'SI', 'GR',\n",
       "       'BB', 'CM', 'IS', 'SE', 'RU', 'DZ', 'VE', 'UY', 'ZA', 'IM', 'LB',\n",
       "       'CR', 'IL', 'CN', 'DK', 'CO', 'EC', 'JE'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this list of countries is from the dataset itself - interesting could look for an option to join?\n",
    "\n",
    "#eureka: why not count the number of countries (each country) from df1['previous_payouts'] - and create that many empty rows\n",
    "#in the dataset and then merge ? should check whether the same method would work for df1['ticket_types'] too?! but this is great - ideas are always great - happy!\n",
    "df1['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1.groupby(['country']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pay_new=df_payouts.groupby(['country'])\n",
    "len(df_pay_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Keep only date part when using pandas.to_datetime\n",
    "\n",
    "df1['approx_payout_date']=df1['approx_payout_date'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['event_created']=df1['event_created'].dt.date\n",
    "df1['event_end']=df1['event_end'].dt.date\n",
    "df1['event_start'] = df1['event_start'].dt.date\n",
    "df1['user_created'] = df1['user_created'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fraudster_event', 'premium', 'spammer_warn', 'fraudster',\n",
       "       'spammer_limited', 'spammer_noinvite', 'locked', 'tos_lock',\n",
       "       'tos_warn', 'fraudster_att', 'spammer_web', 'spammer'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#going to convert the acc_type column values based on the values in the same column. for example: if 'fraud' appears in the column then\n",
    "#say True for being a fraud transaction or say False for being not a fraud transaction\n",
    "#first check the unique values of the column: acct_type\n",
    "df1['acct_type'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#to convert the values of the column: acct_type\n",
    "#if value: 'fraudster' appear then 1 as value or 0\n",
    "\n",
    "df1['acct_type'] = df1['acct_type'].replace(['fraudster_event', 'fraudster', 'fraudster'], 1)\n",
    "\n",
    "df1['acct_type']=df1['acct_type'].replace(['premium', 'spammer_warn','spammer_limited', 'spammer_noinvite', 'locked', 'tos_lock','tos_warn','spammer_web', 'spammer'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "10       0\n",
       "11       0\n",
       "12       0\n",
       "13       0\n",
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "18       0\n",
       "19       0\n",
       "20       0\n",
       "21       0\n",
       "22       0\n",
       "23       0\n",
       "24       0\n",
       "25       0\n",
       "26       1\n",
       "27       0\n",
       "28       0\n",
       "29       0\n",
       "        ..\n",
       "14307    0\n",
       "14308    0\n",
       "14309    0\n",
       "14310    0\n",
       "14311    0\n",
       "14312    0\n",
       "14313    0\n",
       "14314    0\n",
       "14315    0\n",
       "14316    1\n",
       "14317    0\n",
       "14318    1\n",
       "14319    0\n",
       "14320    0\n",
       "14321    0\n",
       "14322    0\n",
       "14323    0\n",
       "14324    0\n",
       "14325    1\n",
       "14326    0\n",
       "14327    0\n",
       "14328    0\n",
       "14329    0\n",
       "14330    0\n",
       "14331    0\n",
       "14332    1\n",
       "14333    0\n",
       "14334    0\n",
       "14335    0\n",
       "14336    1\n",
       "Name: acct_type, Length: 14337, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['acct_type']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
