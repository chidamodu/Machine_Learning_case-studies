{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# if sys.version_info[0]>=3: raw_input=input\n",
    "transformer=HashingVectorizer(stop_words='english')\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "with open('/Users/ralagianambi/Desktop/document_classify.txt', \"r\") as fname:\n",
    "    for i in fname:\n",
    "        s=i.rstrip()\n",
    "        idx=s.find(' ')\n",
    "        X_train.append(s[idx+1:])\n",
    "        y_train.append(int(s[:idx]))\n",
    "\n",
    "train = transformer.fit_transform(X_train)\n",
    "svm=LinearSVC()\n",
    "svm.fit(train,y_train)\n",
    "\n",
    "# y_train, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " We can say that the value of Y depends on m features. Andrea studies this equation for n different feature sets (f1, f2,..., fm) and records each respective value of Y. If she has q new feature sets, can you help Andrea find the value of Y for each of the sets?\n",
      "Project Earth, California's biggest environmental organization, is working to protect the planet Earth from global warming. Dr. Ritika is a scientist at Project Earth. \n",
      "Navigate your code with ease. In select public repositories, you can now click on function and method calls to jump to their definitions in the same repository.\n",
      "Query an alphabetically ordered list of all names in OCCUPATIONS, immediately followed by the first letter of each profession as a parenthetical (i.e.: enclosed in parentheses). For example: AnActorName(A), ADoctorName(D), AProfessorName(P), and ASingerName(S).\n",
      "The first column is an alphabetically ordered list of Doctor names. \n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "X_test=[]\n",
    "for i in range(int(input())):\n",
    "    input_text=input().rstrip()\n",
    "    X_test.append(input_text)\n",
    "test = transformer.transform(X_test)\n",
    "y_test=svm.predict(test)\n",
    "for e in y_test: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk takes a long time to execute\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# ps=PorterStemmer()\n",
    "# # from sklearn.feature_extraction.text import CountVectorizer\n",
    "# def document_classify(f):\n",
    "#     transformer=HashingVectorizer(stop_words='english')\n",
    "#     X_train=[]\n",
    "#     y_train=[]\n",
    "    \n",
    "    \n",
    "#     with open(f, \"r\") as fname:\n",
    "#         for i in fname:\n",
    "#             s=i.rstrip()\n",
    "#             idx=s.find(' ')\n",
    "#             xtrain=[kelime for kelime in s[idx+1:] if not kelime in set(stopwords.words(\"english\"))]\n",
    "#             X_train.append(xtrain)\n",
    "#             y_train.append(int(s[:idx]))\n",
    "#     print(y_train)\n",
    "    \n",
    "#     for j in X_train:\n",
    "#         xtrain=j.lower()\n",
    "#         xtrain=nltk.word_tokenize(xtrain)\n",
    "#         xtrain=[ps.stem(kelime) for kelime in xtrain if not kelime in set(stopwords.words(\"english\"))]\n",
    "#         xtrain=' '.join(xtrain)\n",
    "#     print(X_train)\n",
    "#     train = transformer.fit_transform(xtrain)\n",
    "#     svm=LinearSVC()\n",
    "#     svm.fit(train,y_train)\n",
    "#     X_test=[]\n",
    "#     for i in range(int(input())):\n",
    "#         input_text=input().rstrip()\n",
    "#         X_test.append(input_text)\n",
    "#         test = transformer.transform(X_test)\n",
    "#         y_test=svm.predict(test)\n",
    "#     for e in y_test: print(e)\n",
    "    \n",
    "    \n",
    "# document_classify('/Users/ralagianambi/Desktop/document_classify.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV\n",
    "Project Earth, California's biggest environmental organization, is working to protect the planet Earth from global warming. Dr. Ritika is a scientist at Project Earth.\n",
    "We can say that the value of Y depends on m features. Andrea studies this equation for n different feature sets (f1, f2,..., fm) and records each respective value of Y. If she has q new feature sets, can you help Andrea find the value of Y for each of the sets?\n",
    "2\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralagianambi/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/ralagianambi/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Project Earth, California's biggest environmental organization, is working to protect the planet Earth from global warming. Dr. Ritika is a scientist at Project Earth.\n",
      "We can say that the value of Y depends on m features. Andrea studies this equation for n different feature sets (f1, f2,..., fm) and records each respective value of Y. If she has q new feature sets, can you help Andrea find the value of Y for each of the sets?\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Going to try with logistic regression\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "def document_classify(f):\n",
    "    transformer=HashingVectorizer(stop_words='english')\n",
    "    X_train=[]\n",
    "    y_train=[]\n",
    "\n",
    "    with open(f, \"r\") as fname:\n",
    "        for i in fname:\n",
    "            s=i.rstrip()\n",
    "            idx=s.find(' ')\n",
    "            X_train.append(s[idx+1:])\n",
    "            y_train.append(int(s[:idx]))\n",
    "#     print(y_train)\n",
    "    train = transformer.fit_transform(X_train)\n",
    "    svm=LogisticRegression()\n",
    "    svm.fit(train,y_train)\n",
    "    X_test=[]\n",
    "    for i in range(int(input())):\n",
    "        input_text=input().rstrip()\n",
    "        X_test.append(input_text)\n",
    "        test = transformer.transform(X_test)\n",
    "        y_test=svm.predict(test)\n",
    "    for e in y_test: print(e)\n",
    "    \n",
    "    \n",
    "document_classify('/Users/ralagianambi/Desktop/document_classify.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Project Earth, California's biggest environmental organization, is working to protect the planet Earth from global warming. Dr. Ritika is a scientist at Project Earth.\n",
    "We can say that the value of Y depends on m features. Andrea studies this equation for n different feature sets (f1, f2,..., fm) and records each respective value of Y. If she has q new feature sets, can you help Andrea find the value of Y for each of the sets?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
